# Key Roles of checkpointLocation
# 1. Fault Tolerance & Recovery: f your Spark application fails (due to a cluster crash, JVM error, or network issue), Spark uses the data in the checkpoint directory to resume processing.
# 2. Maintain State Information for stateful transformations: For stateful queries (like window(), groupBy(), or dropDuplicates()), Spark must remember intermediate results (e.g., a running count). It saves this "state" into the checkpoint location so that if the job restarts, the running totals aren't lost.
# 3. Exactly-once semantics for output sinks that support it.

- Complete Mode : All the changes made due to the addition of a new
file along the previous results will be reflected in the output. The entire
updated result table will be written to the external storage.
  
- Update Mode : UPSERT(Update+Insert) Only the updates and inserts
made as per the new file added will reflect in the output. Only the rows
that are updated or newly inserted will be written to the external
storage. 
if the values (say A) present in previous batch data, but not present in the latest batch data. then A will not present in the 
output of latest batch processing.
if the values (say A) present in previous batch data, but also present in the latest batch data. then A will present with the updated 
output of latest batch processing, means prev + latest data.
if the values (say A) not present in previous batch data, but present in the latest batch data. then A will present in the 
output of latest batch processing.
  
- Append Mode : Append mode doesnâ€™t work on Aggregation operations.
Only the new records added will be shown.
